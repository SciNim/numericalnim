steepest_descent	numericalnim/optimize.html#steepest_descent,proc(float64),float64,float64,float64,Natural	optimize: steepest_descent(deriv: proc (x: float64): float64; start: float64;\n                 gamma: float64 = 0.01; precision: float64 = 0.00001;\n                 max_iters: Natural = 1000): float64	
conjugate_gradient	numericalnim/optimize.html#conjugate_gradient,Tensor[T],Tensor[T],Tensor[T],float64	optimize: conjugate_gradient[T](A, b, x_0: Tensor[T]; tolerance: float64): Tensor[T]	
newtons	numericalnim/optimize.html#newtons,proc(float64),proc(float64),float64,float64,Natural	optimize: newtons(f: proc (x: float64): float64; deriv: proc (x: float64): float64;\n        start: float64; precision: float64 = 0.00001; max_iters: Natural = 1000): float64	
secant	numericalnim/optimize.html#secant,proc(float64),array[,float64],float64,Natural	optimize: secant(f: proc (x: float64): float64; start: array[2, float64];\n       precision: float64 = 0.00001; max_iters: Natural = 1000): float64	
Armijo	numericalnim/optimize.html#Armijo	LineSearchCriterion.Armijo	
Wolfe	numericalnim/optimize.html#Wolfe	LineSearchCriterion.Wolfe	
WolfeStrong	numericalnim/optimize.html#WolfeStrong	LineSearchCriterion.WolfeStrong	
NoLineSearch	numericalnim/optimize.html#NoLineSearch	LineSearchCriterion.NoLineSearch	
LineSearchCriterion	numericalnim/optimize.html#LineSearchCriterion	optimize: LineSearchCriterion	
OptimOptions	numericalnim/optimize.html#OptimOptions	optimize: OptimOptions	
StandardOptions	numericalnim/optimize.html#StandardOptions	optimize: StandardOptions	
LevMarqOptions	numericalnim/optimize.html#LevMarqOptions	optimize: LevMarqOptions	
LBFGSOptions	numericalnim/optimize.html#LBFGSOptions	optimize: LBFGSOptions	
optimOptions	numericalnim/optimize.html#optimOptions,U,U,bool,int,LineSearchCriterion	optimize: optimOptions[U](tol: U = U(0.000001); alpha: U = U(1); fastMode: bool = false;\n                maxIterations: int = 10000;\n                lineSearchCriterion: LineSearchCriterion = NoLineSearch): OptimOptions[\n    U, StandardOptions]	
steepestDescentOptions	numericalnim/optimize.html#steepestDescentOptions,U,U,bool,int,LineSearchCriterion	optimize: steepestDescentOptions[U](tol: U = U(0.000001); alpha: U = U(0.001);\n                          fastMode: bool = false; maxIterations: int = 10000;\n    lineSearchCriterion: LineSearchCriterion = NoLineSearch): OptimOptions[U,\n    StandardOptions]	
newtonOptions	numericalnim/optimize.html#newtonOptions,U,U,bool,int,LineSearchCriterion	optimize: newtonOptions[U](tol: U = U(0.000001); alpha: U = U(1); fastMode: bool = false;\n                 maxIterations: int = 10000;\n                 lineSearchCriterion: LineSearchCriterion = NoLineSearch): OptimOptions[\n    U, StandardOptions]	
bfgsOptions	numericalnim/optimize.html#bfgsOptions,U,U,bool,int,LineSearchCriterion	optimize: bfgsOptions[U](tol: U = U(0.000001); alpha: U = U(1); fastMode: bool = false;\n               maxIterations: int = 10000;\n               lineSearchCriterion: LineSearchCriterion = NoLineSearch): OptimOptions[\n    U, StandardOptions]	
lbfgsOptions	numericalnim/optimize.html#lbfgsOptions,int,U,U,bool,int,LineSearchCriterion	optimize: lbfgsOptions[U](savedIterations: int = 10; tol: U = U(0.000001);\n                alpha: U = U(1); fastMode: bool = false;\n                maxIterations: int = 10000;\n                lineSearchCriterion: LineSearchCriterion = NoLineSearch): OptimOptions[\n    U, LBFGSOptions[U]]	
levmarqOptions	numericalnim/optimize.html#levmarqOptions,U,U,U,bool,int,LineSearchCriterion	optimize: levmarqOptions[U](lambda0: U = U(1); tol: U = U(0.000001); alpha: U = U(1);\n                  fastMode: bool = false; maxIterations: int = 10000;\n                  lineSearchCriterion: LineSearchCriterion = NoLineSearch): OptimOptions[\n    U, LevMarqOptions[U]]	
vectorNorm	numericalnim/optimize.html#vectorNorm,Tensor[T]	optimize: vectorNorm[T](v: Tensor[T]): T	
line_search	numericalnim/optimize.html#line_search,U,Tensor[T],Tensor[U],proc(Tensor[U]),LineSearchCriterion,bool	optimize: line_search[U, T](alpha: var U; p: Tensor[T]; x0: Tensor[U];\n                  f: proc (x: Tensor[U]): T; criterion: LineSearchCriterion;\n                  fastMode: bool = false)	
steepestDescent	numericalnim/optimize.html#steepestDescent,proc(Tensor[U]),Tensor[U],OptimOptions[U,StandardOptions],proc(Tensor[U])	optimize: steepestDescent[U; T: not Tensor](f: proc (x: Tensor[U]): T; x0: Tensor[U];\n    options: OptimOptions[U, StandardOptions] = steepestDescentOptions[U]();\n    analyticGradient: proc (x: Tensor[U]): Tensor[T] = nil): Tensor[U]	
newton	numericalnim/optimize.html#newton,proc(Tensor[U]),Tensor[U],OptimOptions[U,StandardOptions],proc(Tensor[U])	optimize: newton[U; T: not Tensor](f: proc (x: Tensor[U]): T; x0: Tensor[U]; options: OptimOptions[\n    U, StandardOptions] = newtonOptions[U]();\n                         analyticGradient: proc (x: Tensor[U]): Tensor[T] = nil): Tensor[\n    U]	
bfgs_old	numericalnim/optimize.html#bfgs_old,proc(Tensor[U]),Tensor[U],U,U,bool,proc(Tensor[U])	optimize: bfgs_old[U; T: not Tensor](f: proc (x: Tensor[U]): T; x0: Tensor[U];\n                           alpha: U = U(1); tol: U = U(0.000001);\n                           fastMode: bool = false; analyticGradient: proc (\n    x: Tensor[U]): Tensor[T] = nil): Tensor[U]	
bfgs	numericalnim/optimize.html#bfgs,proc(Tensor[U]),Tensor[U],OptimOptions[U,StandardOptions],proc(Tensor[U])	optimize: bfgs[U; T: not Tensor](f: proc (x: Tensor[U]): T; x0: Tensor[U]; options: OptimOptions[\n    U, StandardOptions] = bfgsOptions[U]();\n                       analyticGradient: proc (x: Tensor[U]): Tensor[T] = nil): Tensor[\n    U]	
lbfgs	numericalnim/optimize.html#lbfgs,proc(Tensor[U]),Tensor[U],OptimOptions[U,LBFGSOptions[U]],proc(Tensor[U])	optimize: lbfgs[U; T: not Tensor](f: proc (x: Tensor[U]): T; x0: Tensor[U]; options: OptimOptions[\n    U, LBFGSOptions[U]] = lbfgsOptions[U]();\n                        analyticGradient: proc (x: Tensor[U]): Tensor[T] = nil): Tensor[\n    U]	
levmarq	numericalnim/optimize.html#levmarq,proc(Tensor[U],U),Tensor[U],Tensor[U],Tensor[T: not Tensor],OptimOptions[U,LevMarqOptions[U]],Tensor[T: not Tensor]	optimize: levmarq[U; T: not Tensor](f: proc (params: Tensor[U]; x: U): T;\n                          params0: Tensor[U]; xData: Tensor[U];\n                          yData: Tensor[T]; options: OptimOptions[U,\n    LevMarqOptions[U]] = levmarqOptions[U]();\n                          yError: Tensor[T] = ones_like(yData)): Tensor[U]	
paramUncertainties	numericalnim/optimize.html#paramUncertainties,Tensor[U],proc(Tensor[U],U),Tensor[U],Tensor[T],Tensor[T]	optimize: paramUncertainties[U; T](params: Tensor[U];\n                         fitFunc: proc (params: Tensor[U]; x: U): T;\n                         xData: Tensor[U]; yData: Tensor[T]; yError: Tensor[T];\n                         returnFullCov = false): Tensor[T]	
Optimization	numericalnim/optimize.html#optimization	 Optimization	
Optimization	numericalnim/optimize.html#optimization-optimization	  Optimization	
Curve fitting	numericalnim/optimize.html#optimization-curve-fitting	  Curve fitting	
